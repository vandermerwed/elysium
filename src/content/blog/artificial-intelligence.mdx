---
pubDatetime: 2024-05-25T04:26:00
title: On Artificial Intelligence
slug: artificial-intelligence
featured: false
draft: false
tags:
  - ai
  - technology
  - ethics
  - manifesto
description: Some thoughts on Artificial Intelligence and responsible use thereof.
type: note
aiUsage:
  - code-assistance
  - research
  - proofreading
---

import AidaNotice from "@components/AidaNotice.astro";

## Table of contents

## A World Built on AI

<br />

> Caffeine equips us to cope with the world caffeine helped us to create.

&mdash; Michael Pollan, <cite>Caffeine: How Caffeine Created the Modern World</cite> [^1]

<br />

If you replace "Caffeine" with "AI" in the quote above, it perfectly captures our current trajectory.
We rely on AI to be productive, to find inspiration, and, just like caffeine, it's becoming an essential component of our daily lives.
However, AI has the power to strip us of our [agency](https://sociologydictionary.org/agency/) in ways caffeine never could.

Sure, one could argue that caffeine physically enters our bodies while AI does not. At least, not yet. [Neural implants](https://neuralink.com/blog/prime-study-progress-update-second-participant/) may change that soon enough.
Another way to look at it is that we feed our brains with information, just as we feed our bodies with food.
Our devices become extensions of ourselves. We are increasingly outsourcing our thinking and decision-making to algorithms.
If you've ever experienced that uneasy feeling when leaving home without your phone, you know just how deeply intertwined our identities have become with our technologies.

Despite this, I'm not entirely pessimistic about AI. I do believe there is a possible future where things turn out fine, but it won't happen without effort on our part.
While there's plenty of fear-mongering online about AI wiping out or enslaving humanity, I'm more concerned about a different kind of future.
Not the [Skynet](https://en.wikipedia.org/wiki/Skynet_(Terminator)) scenario from Terminator, but something closer to the future depicted in [WALL·E](https://www.imdb.com/title/tt0910970/).

## The WALL·E Future

If you haven't seen WALL·E, the film portrays a future where humans have surrendered all agency to technology and AI.
In this future, every aspect of life is automated. People have become so dependent that even the act of walking has become obsolete.
Their existence revolves around constant consumption, with technology managing everything else.
This future is far more plausible than the one depicted by *Terminator*, and it terrifies me.

Right now, we're racing toward this WALL·E future at breakneck speed. The [boiling frog metaphor](https://en.wikipedia.org/wiki/Boiling_frog) comes to mind.
Humans are often slow to act, especially if change threatens our convenience, wealth, and power.
Just look at the climate crisis for a glaring example.

## Using AI Responsibly

I still plan to use AI, but with safeguards in place to ensure I use it responsibly and thoughtfully, despite my concerns.
I intend to pass these guiding principles on to my children and share them with anyone willing to listen.
AI is proof that memorising facts won't serve us well in the long run.
What matters, now more than ever, are skills like focus, critical thinking, logical reasoning, and the ability to discern truth from fiction.
Through this lens, the shortcomings of our education systems are glaringly obvious. However, that's a topic for another day.

Here are my guiding principles for using AI responsibly:
- **Transparency in AI Usage:** Always disclose when and how AI is involved in content creation.
- **AI as an Assistive Tool:** Use AI to support your creative process, not to replace your own thinking and originality. Remember, it can mimic you but it can never *be* you.
- **Personal Authorship:** Write the first draft yourself and personally proofread the final version to ensure authenticity and accuracy.
- **Clear Objectives:** Employ AI tools when you have a clear goal in mind. Avoid using it without a defined outcome to prevent aimless or irrelevant results.
- **Awareness of Limitations and Biases:** Understand that AI is trained on data that may contain biases and can sometimes produce inaccurate or misleading information. It can even fabricate details, a phenomenon known as "confabulation" (a.k.a "hallucination"). Do not let AI fill in gaps without verification.
- **Responsible and Ethical Use:** Use AI sparingly and responsibly, acknowledging its unknown long-term effects. Ensure that your use of AI adheres to ethical standards and does not contribute to misinformation or harm.

## Actions Speak Louder Than Words

To hold myself accountable, I created an [AI Manifesto](/ai) page, inspired by [these](https://www.bydamo.la/p/ai-manifesto) [great](https://rknight.me/ai/) [examples](https://yordi.me/ai/).

I also disclose how I use AI for creating content and code on this website.
At the bottom of this post, you'll find an example of this, as well as every other post here.
If you're curious about how it all works, I explain it in the section on [how I use AI for writing](/ai#writing) on my AI Manifesto page.

## Final Thoughts

AI is an unprecedented anomaly in human history, and it will inevitably impact every industry.
While we've witnessed transformative innovations before, like the invention of electricity or the rise of the internet, this time feels different.
The accessibility and rapid advancement of AI have changed the game.
It is embedding itself into every sector at an alarming rate, as evidenced by all the [sparkles ✨](https://bigmedium.com/ideas/your-sparkles-are-fizzling.html) popping up in almost every software tool we use.

AI mimics intelligence by speaking well, but speaking well is not the same as thinking well. We often fall for this with humans too. [^2]
Throughout history, there are countless examples where people were misled by confident charlatans that spoke well.

<br />

> The AI-written contract may be better than a human-written one.
> But can you trust it? After all, if you're not a lawyer, you don't know what you don't know.
> And the fact that the AI contract looks so similar to a human one makes it easy for you to take its provenance for granted.
> That is, the better the outcome looks to your non-specialist eyes, the more likely you are to give up your agency.

&mdash; Jorge Arango, <cite>Exploring the AI Solution Space</cite> [^3]

<br />

And herein lies the problem. If we trust that AI is correct without validating its correctness, we have given up our agency.

## Further reading:

Here are some more interesting thoughts and links on the topic of AI that aren't directly mentioned above.
I'll keep adding to this list as I discover more interesting or thought-provoking takes on AI:

- [SlashAI: A Hub for AI Manifestos](https://slashai.page/)
- [Maggie Appleton on Generative Forgery](https://maggieappleton.com/generative-forgery)
- [Rach Smith on AI Is for the Idea Guys](https://rachsmith.com/ai-is-for-the-idea-guys/)
- [Rach Smith on Wanting Better Search](https://rachsmith.com/i-want-good-search/)
- [Microsoft's Guide to Using Generative AI Responsibly](https://github.com/microsoft/generative-ai-for-beginners/blob/main/03-using-generative-ai-responsibly/README.md)

## Footnotes

[^1]: Michael Pollan, [Caffeine: How Caffeine Created the Modern World](https://www.goodreads.com/book/show/52300107-caffeine)
[^2]: Josh Clark, [Exploring the AI Solution Space](https://bigmedium.com/ideas/links/exploring-the-ai-solution-space-jorge-arango.html)
[^3]: Jorge Arango, [Exploring the AI Solution Space](https://jarango.com/2024/10/01/exploring-the-ai-solution-space/)